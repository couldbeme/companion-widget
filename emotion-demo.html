<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Riley ‚Äî The AI That Feels With You</title>
  <link rel="stylesheet" href="style.css">
  <style>
    .demo-container {
      text-align: center;
      max-width: 600px;
      margin: 0 auto;
    }
    
    .tagline {
      font-family: 'VT323', monospace;
      font-size: 24px;
      color: #00ffff;
      margin-bottom: 30px;
      text-shadow: 0 0 10px #00ffff;
    }
    
    .mic-button {
      width: 80px;
      height: 80px;
      border-radius: 50%;
      border: 4px solid #00ffff;
      background: linear-gradient(135deg, #1a1a2e, #16213e);
      color: #00ffff;
      font-size: 32px;
      cursor: pointer;
      margin: 20px auto;
      display: flex;
      align-items: center;
      justify-content: center;
      transition: all 0.2s;
      box-shadow: 0 0 20px rgba(0, 255, 255, 0.3);
    }
    
    .mic-button:hover {
      transform: scale(1.1);
      box-shadow: 0 0 30px rgba(0, 255, 255, 0.5);
    }
    
    .mic-button.recording {
      border-color: #ff4444;
      background: linear-gradient(135deg, #2a1a1a, #3e1616);
      box-shadow: 0 0 30px rgba(255, 68, 68, 0.5);
      animation: pulse-red 1s infinite;
    }
    
    @keyframes pulse-red {
      0%, 100% { box-shadow: 0 0 20px rgba(255, 68, 68, 0.5); }
      50% { box-shadow: 0 0 40px rgba(255, 68, 68, 0.8); }
    }
    
    .status-text {
      font-family: 'VT323', monospace;
      font-size: 20px;
      color: #808080;
      margin: 15px 0;
    }
    
    .transcript {
      font-family: 'VT323', monospace;
      font-size: 22px;
      color: #e0e0e0;
      background: rgba(0, 255, 255, 0.1);
      border: 1px solid rgba(0, 255, 255, 0.3);
      border-radius: 10px;
      padding: 20px;
      margin: 20px 0;
      min-height: 60px;
      text-align: left;
    }
    
    .emotion-display {
      display: flex;
      align-items: center;
      justify-content: center;
      gap: 15px;
      margin: 20px 0;
    }
    
    .emotion-emoji {
      font-size: 48px;
      animation: bounce 0.5s ease-out;
    }
    
    @keyframes bounce {
      0%, 100% { transform: scale(1); }
      50% { transform: scale(1.2); }
    }
    
    .emotion-label {
      font-family: 'VT323', monospace;
      font-size: 28px;
      text-transform: uppercase;
    }
    
    .emotion-label.happy { color: #FFD700; }
    .emotion-label.sad { color: #6495ED; }
    .emotion-label.angry { color: #FF4444; }
    .emotion-label.surprised { color: #FF69B4; }
    .emotion-label.fearful { color: #9370DB; }
    .emotion-label.disgusted { color: #32CD32; }
    .emotion-label.neutral { color: #00FFFF; }
    
    .instructions {
      font-family: 'VT323', monospace;
      font-size: 18px;
      color: #606060;
      margin-top: 30px;
    }

    .credit {
      font-family: 'VT323', monospace;
      font-size: 16px;
      color: #404040;
      margin-top: 40px;
    }
    
    .credit a {
      color: #00ffff;
      text-decoration: none;
    }
  </style>
</head>
<body>
  <div class="demo-container">
    <div class="tagline">‚ú® The AI that feels with you ‚ú®</div>
    
    <!-- Floating Companion Avatar -->
    <div class="floating-companion" id="companion">
      <div class="avatar" id="avatar">
        <div class="avatar-face">
          <div class="eye left"></div>
          <div class="eye right"></div>
          <div class="mouth"></div>
        </div>
        <div class="avatar-glow"></div>
      </div>
    </div>
    
    <!-- Emotion Display -->
    <div class="emotion-display" id="emotion-display" style="display: none;">
      <span class="emotion-emoji" id="emotion-emoji">üòê</span>
      <span class="emotion-label neutral" id="emotion-label">neutral</span>
    </div>
    
    <!-- Mic Button -->
    <button class="mic-button" id="mic-btn">üé§</button>
    <div class="status-text" id="status">Hold to speak</div>
    
    <!-- Transcript -->
    <div class="transcript" id="transcript">
      <em style="color: #606060;">Your words will appear here...</em>
    </div>
    
    <div class="instructions">
      Hold the mic button and speak with emotion.<br>
      Try: "I'm so excited!" or "This is really frustrating..."
    </div>
    
    <div class="credit">
      Emotion AI by <a href="https://descriptor.ai">Descriptor.AI</a>
    </div>
  </div>

  <script>
    const API = 'http://localhost:8080';
    const API_KEY = 'test-key-dev-only';
    const DEMO_LIMIT_MS = 3 * 60 * 1000; // 3 minutes
    
    const avatar = document.getElementById('avatar');
    const micBtn = document.getElementById('mic-btn');
    const status = document.getElementById('status');
    const transcript = document.getElementById('transcript');
    const emotionDisplay = document.getElementById('emotion-display');
    const emotionEmoji = document.getElementById('emotion-emoji');
    const emotionLabel = document.getElementById('emotion-label');
    
    const emotionEmojis = {
      happy: 'üòä',
      sad: 'üò¢',
      angry: 'üò†',
      surprised: 'üò≤',
      fearful: 'üò®',
      disgusted: 'ü§¢',
      neutral: 'üòê'
    };
    
    let mediaRecorder;
    let audioChunks = [];
    let demoStartTime = localStorage.getItem('ser_demo_start');
    let demoExpired = localStorage.getItem('ser_demo_expired') === 'true';
    
    function showDemoExpired() {
      demoExpired = true;
      localStorage.setItem('ser_demo_expired', 'true');
      micBtn.disabled = true;
      micBtn.style.opacity = '0.5';
      micBtn.textContent = '‚è±Ô∏è';
      status.textContent = 'Demo complete';
      transcript.innerHTML = `
        <div style="text-align: center;">
          <div style="font-size: 24px; margin-bottom: 15px;">‚ú® Enjoyed the demo?</div>
          <div style="color: #00ffff; margin-bottom: 20px;">Get unlimited access to real-time emotion AI</div>
          <a href="https://descriptor.ai" target="_blank" style="
            display: inline-block;
            padding: 12px 25px;
            background: linear-gradient(135deg, #00ffff, #00ff88);
            color: #1a1a2e;
            text-decoration: none;
            border-radius: 25px;
            font-weight: bold;
          ">Join the Waitlist ‚Üí</a>
        </div>
      `;
    }
    
    // Check on load
    if (demoStartTime && Date.now() - parseInt(demoStartTime) > DEMO_LIMIT_MS) {
      demoExpired = true;
      localStorage.setItem('ser_demo_expired', 'true');
    }
    if (demoExpired) showDemoExpired();
    
    function setEmotion(emotion) {
      // Remove all emotion classes
      avatar.className = 'avatar';
      emotionLabel.className = 'emotion-label';
      
      // Add new emotion
      avatar.classList.add(`emotion-${emotion}`);
      emotionLabel.classList.add(emotion);
      emotionLabel.textContent = emotion;
      emotionEmoji.textContent = emotionEmojis[emotion] || 'üé≠';
      emotionDisplay.style.display = 'flex';
      
      // Animate emoji
      emotionEmoji.style.animation = 'none';
      setTimeout(() => emotionEmoji.style.animation = 'bounce 0.5s ease-out', 10);
    }
    
    micBtn.onmousedown = micBtn.ontouchstart = async (e) => {
      e.preventDefault();
      
      if (demoExpired) {
        showDemoExpired();
        return;
      }
      
      // Start timer on first use
      if (!demoStartTime) {
        demoStartTime = Date.now();
        localStorage.setItem('ser_demo_start', demoStartTime.toString());
      }
      
      // Check if expired
      if (Date.now() - parseInt(demoStartTime) > DEMO_LIMIT_MS) {
        showDemoExpired();
        return;
      }
      
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        micBtn.classList.add('recording');
        status.textContent = 'üî¥ Listening...';
        
        mediaRecorder = new MediaRecorder(stream);
        audioChunks = [];
        
        mediaRecorder.ondataavailable = (e) => audioChunks.push(e.data);
        
        mediaRecorder.onstop = async () => {
          status.textContent = 'üß† Analyzing emotions...';
          
          const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
          const arrayBuffer = await audioBlob.arrayBuffer();
          const audioContext = new AudioContext({ sampleRate: 16000 });
          const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
          const pcmData = audioBuffer.getChannelData(0);
          const wavBlob = encodeWAV(pcmData, 16000);
          
          const formData = new FormData();
          formData.append('file', wavBlob, 'audio.wav');
          
          try {
            const res = await fetch(`${API}/v1/transcribe`, {
              method: 'POST',
              headers: { 'X-API-Key': API_KEY },
              body: formData
            });
            const data = await res.json();
            
            // Update UI
            transcript.innerHTML = `"${data.text || '...'}"`;
            setEmotion(data.emotion || 'neutral');
            status.textContent = 'Hold to speak';
            
          } catch (e) {
            status.textContent = '‚ùå Connection error';
            transcript.innerHTML = `<em style="color: #ff4444;">API Error: ${e.message}</em>`;
          }
          
          stream.getTracks().forEach(t => t.stop());
        };
        
        mediaRecorder.start();
      } catch (e) {
        status.textContent = '‚ùå Mic access denied';
      }
    };
    
    micBtn.onmouseup = micBtn.ontouchend = micBtn.onmouseleave = () => {
      if (mediaRecorder && mediaRecorder.state === 'recording') {
        mediaRecorder.stop();
        micBtn.classList.remove('recording');
      }
    };
    
    // WAV encoder
    function encodeWAV(samples, sampleRate) {
      const buffer = new ArrayBuffer(44 + samples.length * 2);
      const view = new DataView(buffer);
      writeString(view, 0, 'RIFF');
      view.setUint32(4, 36 + samples.length * 2, true);
      writeString(view, 8, 'WAVE');
      writeString(view, 12, 'fmt ');
      view.setUint32(16, 16, true);
      view.setUint16(20, 1, true);
      view.setUint16(22, 1, true);
      view.setUint32(24, sampleRate, true);
      view.setUint32(28, sampleRate * 2, true);
      view.setUint16(32, 2, true);
      view.setUint16(34, 16, true);
      writeString(view, 36, 'data');
      view.setUint32(40, samples.length * 2, true);
      let offset = 44;
      for (let i = 0; i < samples.length; i++) {
        const s = Math.max(-1, Math.min(1, samples[i]));
        view.setInt16(offset, s < 0 ? s * 0x8000 : s * 0x7FFF, true);
        offset += 2;
      }
      return new Blob([buffer], { type: 'audio/wav' });
    }
    
    function writeString(view, offset, string) {
      for (let i = 0; i < string.length; i++) {
        view.setUint8(offset + i, string.charCodeAt(i));
      }
    }
    
    // Demo mode - cycle emotions on avatar click
    let demoEmotions = ['happy', 'sad', 'angry', 'surprised', 'fearful', 'disgusted', 'neutral'];
    let demoIndex = 0;
    avatar.onclick = () => {
      setEmotion(demoEmotions[demoIndex]);
      demoIndex = (demoIndex + 1) % demoEmotions.length;
    };
  </script>
</body>
</html>
